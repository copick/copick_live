{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copick.impl.filesystem import CopickRootFSSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COPICK_CONFIG_PATH = \"../assets/samba_config_jfinder.json\"\n",
    "root = CopickRootFSSpec.from_file(COPICK_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "import random\n",
    "\n",
    "from scipy.stats import ks_2samp\n",
    "\n",
    "\n",
    "\n",
    "class SplitDataset:\n",
    "    def __init__(self, config_file: str):\n",
    "        self.root = CopickRootFSSpec.from_file(config_file)\n",
    "        self.arrs = []\n",
    "        self.tomograms = []\n",
    "\n",
    "        N = len(self.root.runs)\n",
    "        self.particle_map = {o.name: i for i,o in enumerate(self.root.config.pickable_objects)}\n",
    "        self.run_stats_list = [0]*N\n",
    "        for i, run in enumerate(self.root.runs[:N]):\n",
    "            self.tomograms.append(run.name)\n",
    "            counter = defaultdict(int)\n",
    "            percent = defaultdict(float)\n",
    "            all = 0\n",
    "            for pick in run.picks:\n",
    "                if pick.points is not None:\n",
    "                    counter[pick.pickable_object_name] = len(pick.points)\n",
    "                    all += len(pick.points)\n",
    "\n",
    "            \n",
    "            for k in self.particle_map.keys():\n",
    "                if k not in counter:\n",
    "                    counter[k] = 0\n",
    "            \n",
    "            # for k,v in counter.items():\n",
    "            #     percent[k] = v/all\n",
    "            percent = counter\n",
    "            \n",
    "            percent = {k: percent[k] for k in sorted(percent.keys())}\n",
    "            print(i, run.name, percent)\n",
    "            self.run_stats_list[i] = percent\n",
    "\n",
    "        print(f'self.run_stats_list {len(self.run_stats_list)}')\n",
    "        for d in self.run_stats_list:\n",
    "            arr = []\n",
    "            for k,v in d.items():\n",
    "                arr += [self.particle_map[k]]*v\n",
    "            self.arrs.append(arr)\n",
    "        \n",
    "        \n",
    "    def plot_all_distributions(self):\n",
    "        # Choose a colormap\n",
    "        colormap = plt.cm.viridis\n",
    "        # Generate a list of colors from the colormap\n",
    "        colors = [colormap(i / len(self.arrs)) for i in range(len(self.arrs))]\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 1, 1)\n",
    "        for i,arr in enumerate(self.arrs):  \n",
    "            sns.histplot(arr, kde=True, color=colors[i]) #, label=self.tomograms[i])\n",
    "        plt.legend()\n",
    "        plt.title('Histogram')\n",
    "\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # sns.boxplot(data=self.arrs)\n",
    "        # plt.xticks([i for i in range(len(self.arrs))], [f'{i}' for i in range(len(self.arrs))])\n",
    "        # plt.title('Box Plot')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def plot_2dist(self, first: int, second: int, arr=False):\n",
    "        if arr:\n",
    "            arr1 = first\n",
    "            arr2 = second\n",
    "            label1 = 'arr1'\n",
    "            label2 = 'arr2'\n",
    "        else:\n",
    "            arr1 = self.arrs[first]\n",
    "            arr2 = self.arrs[second]\n",
    "            label1 = self.tomograms[first]\n",
    "            label2 = self.tomograms[second]\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 1, 1)\n",
    "        sns.histplot(arr1, kde=True, color='blue', label=label1)\n",
    "        sns.histplot(arr2, kde=True, color='red', label=label2)\n",
    "        plt.legend()\n",
    "        plt.title('Histogram')\n",
    "\n",
    "        # plt.subplot(1, 2, 2)\n",
    "        # sns.boxplot(data=[arr1, arr2])\n",
    "        # plt.xticks([0, 1], [label1, label2])\n",
    "        # plt.title('Box Plot')\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def plot_dist_3arrs(self, arr1, arr2, arr3):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 1, 1)\n",
    "        sns.histplot(arr1, kde=True, color='blue', label='training_dataset')\n",
    "        sns.histplot(arr2, kde=True, color='red', label='test_dataset1')\n",
    "        sns.histplot(arr3, kde=True, color='green', label='test_dataset2')\n",
    "        plt.legend()\n",
    "        plt.title('Histogram')\n",
    "        plt.show()\n",
    "    \n",
    "    def plot_dist_test(self, arr2, arr3):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.subplot(1, 1, 1)\n",
    "        sns.histplot(arr2, kde=True, color='red', label='test_dataset1')\n",
    "        sns.histplot(arr3, kde=True, color='green', label='test_dataset2')\n",
    "        plt.legend()\n",
    "        plt.title('Histogram')\n",
    "        plt.show()\n",
    "    \n",
    "    def is_close_dist(self, first: int, second: int, threshold=0.05):\n",
    "        return self.is_arr_close_dist(self.arrs[first], self.arrs[second], threshold)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def is_arr_close_dist(arr1, arr2, threshold=0.05):\n",
    "        # Kolmogorov-Smirnov test\n",
    "        ks_stat, ks_p_value = ks_2samp(arr1, arr2)\n",
    "\n",
    "        # If the p-value is high (e.g., > 0.05), it suggests that there is no significant difference between the distributions of the two dictionaries' values.\n",
    "        print(f\"KS Statistic: {ks_stat}, P-value: {ks_p_value}\")\n",
    "        return ks_p_value > threshold\n",
    "    \n",
    "    \n",
    "    def make_buckets(self, threshold=0.05):\n",
    "        if len(self.run_stats_list):\n",
    "            stats = copy.deepcopy(self.run_stats_list[0])\n",
    "            self.buckets = [[stats, set([0])]] # list of [defaultdict, set()]\n",
    "        \n",
    "        add_new = True\n",
    "        for i in range(1, len(self.arrs)):\n",
    "            for j in range(len(self.buckets)):\n",
    "                arr1 = self.arrs[i]\n",
    "                arr2 = []\n",
    "                for k,v in self.buckets[j][0].items():\n",
    "                    arr2 += [self.particle_map[k]]*v  \n",
    "                if self.is_arr_close_dist(arr1, arr2, threshold):\n",
    "                    self.buckets[j][0] = {k: self.buckets[j][0][k] + self.run_stats_list[i][k] for k in self.run_stats_list[i].keys()}\n",
    "                    self.buckets[j][1].add(i)\n",
    "                    add_new = False\n",
    "                    break\n",
    "                else:\n",
    "                    add_new = True\n",
    "            \n",
    "            if add_new:  \n",
    "                stats = copy.deepcopy(self.run_stats_list[i])\n",
    "                self.buckets.append([stats, set([i])])\n",
    "\n",
    "        \n",
    "        for bucket in self.buckets:\n",
    "            print(bucket)\n",
    "        \n",
    "        print(f'{len(self.buckets)} buckets')\n",
    "\n",
    "\n",
    "        # Choose a colormap\n",
    "        colormap = plt.cm.viridis\n",
    "        # Generate a list of colors from the colormap\n",
    "        colors = [colormap(i / len(self.buckets)) for i in range(len(self.buckets))]\n",
    "        # visualizing buckets\n",
    "        plt.subplot(1, 1, 1)\n",
    "        for i,bucket in enumerate(self.buckets):\n",
    "            arr = []\n",
    "            for k,v in bucket[0].items():\n",
    "                arr += [self.particle_map[k]]*v\n",
    "            self.arrs.append(arr)  \n",
    "            sns.histplot(arr, kde=True, color=colors[i], label=f'cluster {i}')\n",
    "        plt.legend()\n",
    "        plt.title('Histogram') \n",
    "        \n",
    "\n",
    "    \n",
    "    def random_split_list(self, my_list, ks=[0.6, 0.2, 0.2]):\n",
    "        # Shuffle the original list to ensure randomness\n",
    "        random.shuffle(my_list)\n",
    "        \n",
    "        # Calculate split indices\n",
    "        train = round(ks[0] * len(my_list))\n",
    "        test1 = round(ks[1] * len(my_list))\n",
    "        \n",
    "        # Split the list into three parts\n",
    "        train_set = my_list[:train]\n",
    "        test_set1 = my_list[train:train+test1]\n",
    "        test_set2 = my_list[train+test1:]\n",
    "        \n",
    "        return train_set, test_set1, test_set2\n",
    "\n",
    "    \n",
    "    def id2arr(self, ids):\n",
    "        arr = []\n",
    "        for i in ids:\n",
    "            arr = arr + self.arrs[i]\n",
    "        return arr\n",
    "\n",
    "    def generate_datasets(self, ks=[0.6, 0.2, 0.2]):\n",
    "        #self.make_buckets()\n",
    "        train_dt = [] \n",
    "        test_dt1 = []\n",
    "        test_dt2 = []\n",
    "        for bucket in self.buckets:\n",
    "            train_set, test_set1, test_set2 = self.random_split_list(list(bucket[1]), ks)\n",
    "            train_dt = train_dt + train_set\n",
    "            test_dt1 = test_dt1 + test_set1\n",
    "            test_dt2 = test_dt2 + test_set2\n",
    "\n",
    "        train_dataset = [self.tomograms[i] for i in train_dt] \n",
    "        test_dataset1 = [self.tomograms[i] for i in test_dt1]\n",
    "        test_dataset2 = [self.tomograms[i] for i in test_dt2] \n",
    " \n",
    "        train_arr = self.id2arr(train_dt)\n",
    "        test_arr1 = self.id2arr(test_dt1)\n",
    "        test_arr2 = self.id2arr(test_dt2)\n",
    "        self.plot_dist_3arrs(train_arr, test_arr1, test_arr2) \n",
    "        self.plot_dist_test(test_arr1, test_arr2) \n",
    "        return train_dataset, test_dataset1, test_dataset2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = SplitDataset(COPICK_CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.plot_all_distributions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.make_buckets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset1, test_dataset2 = datasets.generate_datasets()\n",
    "print(f'train_dataset\\n{train_dataset}\\ntest_dataset1\\n{test_dataset1}\\ntest_dataset2\\n{test_dataset2}')\n",
    "print(len(train_dataset), len(test_dataset1), len(test_dataset2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the datasets\n",
    "\n",
    "```\n",
    "for each fake model in [sigma = 0, sigma = 1, sigma = 10]:\n",
    "    for each tomogram:\n",
    "        for each particle type:\n",
    "            newpicks = []\n",
    "            for each point in ground truth/jfinder picks:\n",
    "                point[0] += gaussian(sigma)\n",
    "                point[1] += gaussian(sigma)\n",
    "                point[2] += gaussian(sigma)\n",
    "                # TODO add clipping to check that points stay within tomogram dimensions\n",
    "                newpicks.append(point)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def gaussian_function(x, mu=0.0, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Calculate the value of the Gaussian function for a given x, mean (mu), and standard deviation (sigma).\n",
    "    \n",
    "    Parameters:\n",
    "    x (float): The value at which to evaluate the Gaussian function.\n",
    "    mu (float): The mean of the Gaussian distribution.\n",
    "    sigma (float): The standard deviation of the Gaussian distribution.\n",
    "    \n",
    "    Returns:\n",
    "    float: The value of the Gaussian function at x.\n",
    "    \"\"\"\n",
    "    coefficient = 1.0 / (sigma * math.sqrt(2 * math.sqrt(math.pi)))\n",
    "    exponent = -((x - mu) ** 2) / (2 * sigma ** 2)\n",
    "    return coefficient * math.exp(exponent)\n",
    "\n",
    "# Example usage:\n",
    "x_value = 1.0\n",
    "\n",
    "result = gaussian_function(x_value)\n",
    "print(\"The value of the Gaussian function at x =\", x_value, \"is\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sigma in [0.0, 1.0, 10.0]:\n",
    "    for i, run in enumerate(root.runs[:10]):\n",
    "        for pick in run.picks:\n",
    "                if pick.points is not None:\n",
    "                    print(pick.pickable_object_name, len(pick.points))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
